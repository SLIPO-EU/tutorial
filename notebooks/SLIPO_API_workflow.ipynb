{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "To run this demo, a file named `secret.py` must be created in the notebook's\n",
    "folder with the following content:\n",
    "\n",
    "```python\n",
    "# Configuration settings\n",
    "\n",
    "# SLIPO workbench installation\n",
    "BASE_URL = 'https://app.dev.slipo.eu'\n",
    "\n",
    "# SLIPO API key\n",
    "API_KEY = 'your API key'\n",
    "```\n",
    "\n",
    "The `API_KEY` value must be set to a valid SLIPO Application Key. The file must be imported before creating a new context:\n",
    "\n",
    "```python\n",
    "from secret import BASE_URL, API_KEY\n",
    "```\n",
    "\n",
    "### Full documentation about the SLIPO API client is available [here](https://slipoframes.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new context for this session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipoframes.context import SlipoContext\n",
    "\n",
    "from secret import BASE_URL, API_KEY\n",
    "\n",
    "ctx = SlipoContext(\n",
    "    base_url = BASE_URL,\n",
    "    requires_ssl = False,\n",
    "    api_key = API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all preconfigured **profiles** available per SLIPO Toolkit component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = ctx.profiles()\n",
    "prof.sort_values(by=['Tool'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute an existing workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run a prespecified data integration workflow that involves all stages (transformation, interlinking, fusion, enrichment, export).\n",
    "\n",
    "Identify the workflow based on its user-specified _name_, its various versions and their executions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processes = ctx.process_query(\n",
    "    'Integrate GET + OSM data for Corfu',\n",
    "    0,\n",
    "    10\n",
    ")\n",
    "\n",
    "exec = processes[['Id','Name','Executed On','Version']]\n",
    "exec.sort_values(by=['Version'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute a **new instance** of this workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow1 = ctx.process_save(1191)\n",
    "workflow1 = ctx.process_start(workflow1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the **status** of this workflow execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow1 = ctx.process_status(workflow1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Render this **workflow** as a graph with all its components and monitor its **progress**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.process_render(workflow1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute successive stages in POI data integration\n",
    "\n",
    "## Transform operation\n",
    "\n",
    "Next, we are going to transform POI datasets into RDF, involving the following steps:\n",
    "\n",
    "* Upload the files `get_pois_v02_corfu_2100.zip` (SHP format) and `osm20_pois_corfu.csv` (CSV format) from the local folder `datasets` to the remote folder `notebooks/datasets`. The remote folder will be created automatically if not already exists. The option `overwrite` is also set to `True` to overwrite any existing files.\n",
    "* Execute two transform operations to convert data from `SHP` and `CSV` format into `N-Triples`.\n",
    "* Check the status of each operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload **shapefile (SHP)** for the first input dataset (get_pois_v02_corfu_2100.zip) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.file_upload('./datasets/get_pois_v02_corfu_2100.zip', 'notebooks/datasets/get_pois_v02_corfu_2100.zip', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload **CSV file** for the second input dataset (osm20_pois_corfu.csv) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.file_upload('./datasets/osm20_pois_corfu.csv', 'notebooks/datasets/osm20_pois_corfu.csv', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload **configuration files** in folder `config` from the local file system to the remote folder `notebooks/config`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.file_upload('./config', 'notebooks/config', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Browse remote user file system to check its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = ctx.file_browse(sort_col='size', format_size=True, sort_asc=False)\n",
    "\n",
    "df_files[df_files['path'].str.startswith(\"notebooks\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Transformation # 1** for the first input dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert SHP input file to N-Triples\n",
    "transform1 = ctx.transform_shapefile(\n",
    "    'notebooks/datasets/get_pois_v02_corfu_2100.zip',\n",
    "    attrCategory='COMBOTYPE',\n",
    "    attrKey='OBJECTID',\n",
    "    attrName='NAME_GR',\n",
    "    attrX='POINT_X',\n",
    "    attrY='POINT_Y',\n",
    "    featureSource='GET',\n",
    "    sourceCRS='EPSG:2100',\n",
    "    targetCRS='EPSG:4326',\n",
    "    defaultLang='el',\n",
    "    mappingSpec='notebooks/config/get_mappings.yml',\n",
    "    classificationSpec='notebooks/config/get_pois_v04_poi_maincategories_en.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Transformation # 2** for the second input dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CSV input file to N-Triples\n",
    "transform2 = ctx.transform_csv(\n",
    "    'notebooks/datasets/osm20_pois_corfu.csv',\n",
    "    attrCategory='type',\n",
    "    attrGeometry='wkt',\n",
    "    attrKey='osm_id',\n",
    "    attrName='name',\n",
    "    attrX='lon',\n",
    "    attrY='lat',\n",
    "    delimiter='|',\n",
    "    featureSource='OpenStreetMap',\n",
    "    profile='OSM_Europe',\n",
    "    quote='',\n",
    "    mappingSpec='notebooks/config/osm_mappings.yml',\n",
    "    classificationSpec='notebooks/config/osm_classification.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check **progress status** of these transform operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform1 = ctx.process_status(transform1)\n",
    "transform2 = ctx.process_status(transform2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interlink operation\n",
    "\n",
    "#### Execute an interlink operation on the **RDF datasets** generated by the previous two transformation operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interlink1 = ctx.interlink(\n",
    "    'SLIPO_equiMatchByNameAndDistance',\n",
    "    left=transform1.output(),\n",
    "    right=transform2.output()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check **progress status** of the interlinking operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interlink1 = ctx.process_status(interlink1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuse Operation\n",
    "\n",
    "#### Fuse the **RDF datasets** generated by operations `transform1` and `transform2` using the **links** from operation `interlink`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuse1 = ctx.fuse(\n",
    "    'SLIPO_default_abMode',\n",
    "    left=transform1.output(),\n",
    "    right=transform2.output(),\n",
    "    links=interlink1.output()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check **progress status** of the fusion operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuse1 = ctx.process_status(fuse1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrich Operation\n",
    "\n",
    "#### Enrich the fused RDF dataset returned from operation `fuse1` with extra properties from **DBpedia**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich1 = ctx.enrich(\n",
    "    'SLIPO_BASIC',\n",
    "    source=fuse1.output()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check **progress status** of this enrichment operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich1 = ctx.process_status(enrich1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Operation\n",
    "\n",
    "#### Export the enriched RDF dataset to a **CSV file** for possible use in a database, a GIS application, analytics, etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export1 = ctx.export_csv(\n",
    "    'SLIPO_default',\n",
    "    enrich1.output(),\n",
    "    delimiter='|',\n",
    "    quote='\"',\n",
    "    sparqlFile='notebooks/config/query.sparql'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check **progress status** for export operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export1 = ctx.process_status(export1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, copy output CSV file to the local file system (for **analytics** with Jupyter notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.process_file_download(export1.output(), target='./output/corfu-integrated-pois.zip', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get integrated RDF triples as a local file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy output RDFfile to local file system\n",
    "ctx.process_file_download(enrich1.output(), target='./output/integrated.nt', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
